{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add project_root to sys.path so Python can find `scripts/`\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_scripts.features_engineering import quicky_data, lag_features_indicators\n",
    "from general_scripts.pipelines import price_model\n",
    "from general_scripts.predict import future_price_prediction\n",
    "from general_scripts.lstm import LSTMModelMultiStep, LSTMModelMultiOutput\n",
    "from general_scripts.helper import CustomizedLoss\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model_type = LSTMModelMultiStep\n",
    "criterion = CustomizedLoss()\n",
    "n_lags = 25\n",
    "n_forecast = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Load dataset\n",
    "file_path_1 = \"../ready_data/cleaned_vn_30_data.csv\"\n",
    "df_1 = pd.read_csv(file_path_1)[['Date', 'VN_30_Close']]\n",
    "df_1.rename(columns={'VN_30_Close': 'VN_30_F1_Close'}, inplace=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vn30f1 = pd.read_csv(\"../VN30F1_Formatted_Cleaned.csv\")[['Date', 'Close']]\n",
    "df_vn30f1['Date'] = pd.to_datetime(df_vn30f1['Date'], format='%d-%m-%y')\n",
    "df_vn30f1.sort_values('Date', inplace=True)\n",
    "df_vn30f1.rename(columns={'Close': 'VN_30_F1_Close'}, inplace=True)\n",
    "df_vn30f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.concat([df_vn30f1, df_1], ignore_index=True).iloc[:-len(df_vn30f1)]\n",
    "df_1['Date'] = pd.to_datetime(df_1['Date'])\n",
    "\n",
    "df_1.sort_values('Date', inplace=True)\n",
    "df_1.reset_index(inplace=True, drop=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vn30f1 = quicky_data(df_vn30f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vn30f1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    baseline = ExponentialSmoothing(\n",
    "    df_vn30f1['VN_30_F1_Close'].iloc[:-n_forecast*(i+1)],\n",
    "    trend='add',            # additive trend\n",
    "    seasonal='add',         # additive seasonality\n",
    "    seasonal_periods=261    # one business‐year ≈ 261 days\n",
    "    ).fit()\n",
    "\n",
    "    # 2) Forecast the next day (one‐step ahead):\n",
    "    price_forecast = baseline.forecast(n_forecast)\n",
    "\n",
    "    # 3) If you want to extract the trend/seasonal forecasts separately:\n",
    "    fitted_components = baseline.fittedvalues  # this is price = level+trend+seasonal\n",
    "    level = baseline.level                     # the “smoothed level” ≈ trend\n",
    "    seasonal = baseline.season                 # the seasonal factors\n",
    "\n",
    "    print(price_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = quicky_data(df_1)\n",
    "df_1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "for i in range(5):\n",
    "    baseline = ExponentialSmoothing(\n",
    "    df_1['VN_30_F1_Close'].iloc[:-n_forecast*(i+1)],\n",
    "    trend='add',            # additive trend\n",
    "    seasonal='add',         # additive seasonality\n",
    "    seasonal_periods=261    # one business‐year ≈ 261 days\n",
    "    ).fit()\n",
    "\n",
    "    # 2) Forecast the next day (one‐step ahead):\n",
    "    price_forecast = baseline.forecast(n_forecast)\n",
    "\n",
    "    # 3) If you want to extract the trend/seasonal forecasts separately:\n",
    "    fitted_components = baseline.fittedvalues  # this is price = level+trend+seasonal\n",
    "    level = baseline.level                     # the “smoothed level” ≈ trend\n",
    "    seasonal = baseline.season                 # the seasonal factors\n",
    "\n",
    "    print(price_forecast)\n",
    "\n",
    "    data = df_1[['residual', 'trend', 'seasonal']]\n",
    "\n",
    "    if i:\n",
    "        data = data.iloc[:-n_forecast*i]\n",
    "    # 🚀 Train the model and get the test set\n",
    "    model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion, tuning=False, train_seq_len=25, test_seq_len=n_forecast, epochs=50)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "# future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Select additional VN-30_F1 statistics for prediction\n",
    "data = df_1\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Select additional VN-30_F1 statistics for prediction\n",
    "data = lag_features_indicators(df_1[[\"VN_30_F1_Close\", 'trend',\n",
    "       'seasonal', 'residual']], ['VN_30_F1_Close'])\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Select additional VN-30_F1 statistics for prediction\n",
    "data = lag_features_indicators(df_1, ['VN_30_F1_Close'])\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Select additional VN-30_F1 statistics for prediction\n",
    "data = lag_features_indicators(df_1, df_1.columns)\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Load dataset\n",
    "file_path_2 = \"../ready_data/vn_30_F1_external_data.csv\"\n",
    "df_2 = pd.read_csv(file_path_2)\n",
    "df_2 = quicky_data(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_2\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lag_features_indicators(df_2, ['VN_30_F1_Close'])\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lag_features_indicators(df_2, df_2.columns)\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Load dataset\n",
    "file_path_3 = \"../ready_data/vn_30_F1_merged_data.csv\"\n",
    "df_3 = pd.read_csv(file_path_3)\n",
    "df_3 = quicky_data(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_3\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lag_features_indicators(df_3, ['VN_30_F1_Close'])\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lag_features_indicators(df_3, df_3.columns)\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lag_features_indicators(df_3, df_1.columns)\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lag_features_indicators(df_3, df_2.columns)\n",
    "\n",
    "# 🚀 Train the model and get the test set\n",
    "model, X_test_tensor, scaler, y_pred = price_model(data, scaler, model_type, criterion)\n",
    "\n",
    "# 🔮 Generate future predictions\n",
    "future_price_prediction(X_test_tensor, data, y_pred, scaler, model, num_days=n_forecast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
